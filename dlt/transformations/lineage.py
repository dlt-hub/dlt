import logging
from typing import TYPE_CHECKING, Any, cast, Optional, Union

import sqlglot
import sqlglot.expressions as sge
from sqlglot.errors import ParseError, OptimizeError
from sqlglot.expressions import DataType, DATA_TYPE
from sqlglot.schema import Schema as SQLGlotSchema, ensure_schema
from sqlglot.optimizer.annotate_types import annotate_types
from sqlglot.optimizer.qualify import qualify

from dlt.common.libs.sqlglot import (
    to_sqlglot_type,
    from_sqlglot_type,
)
from dlt.common.schema.typing import (
    TTableSchemaColumns,
    TColumnSchema,
)
from dlt.common.schema import Schema
from dlt.destinations.sql_client import SqlClientBase
from dlt.transformations.exceptions import LineageFailedException

if TYPE_CHECKING:
    from dlt.destinations.dataset import ReadableDBAPIDataset
else:
    ReadableDBAPIDataset = Any

logger = logging.getLogger(__file__)


def create_sqlglot_schema(
    sql_client: SqlClientBase[Any],
    schema: Schema,
) -> SQLGlotSchema:
    """Create an SQLGlot schema using a dlt Schema and the destination capabilities.

    The SQLGlot schema automatically includes the database and catalog names if available.
    This can allow cross-dataset transformations on the same physical location.
    """
    mapping_schema: dict[str, dict[str, DATA_TYPE]] = {}  # {table: {col: type}}
    for table_name, table in schema.tables.items():
        table_name = sql_client.make_qualified_table_name_path(table_name, escape=False)[-1]
        if mapping_schema.get(table_name) is None:
            mapping_schema[table_name] = {}

        for column_name, column in table["columns"].items():
            mapping_schema[table_name][column_name] = to_sqlglot_type(
                dlt_type=column["data_type"],
                nullable=column.get("nullable"),
                precision=column.get("precision"),
                scale=column.get("scale"),
                timezone=column.get("timezone"),
            )

    dataset_catalog = sql_client.make_qualified_table_name_path(None, escape=False)
    if len(dataset_catalog) == 2:
        catalog, database = dataset_catalog
        nested_schema = {catalog: {database: mapping_schema}}
    else:
        (database,) = dataset_catalog
        nested_schema = {database: mapping_schema}  # type: ignore

    return ensure_schema(nested_schema)


# TODO should we raise an exception for anonymous columns?
# NOTE even if `infer_sqlglot_schema=True`, some queries haved undetermined final columns
def compute_columns_schema(
    sql_query: str,
    sqlglot_schema: SQLGlotSchema,
    dialect: str,
    infer_sqlglot_schema: bool = True,
    allow_anonymous_columns: bool = True,
    allow_partial: bool = True,
    resource_name: str = None,
) -> TTableSchemaColumns:
    """Compute the expected dlt columns schema for the output of an SQL SELECT query.

    Args:
        infer_sqlglot_schema (bool): If False, all columns and tables referenced must be derived from the SQLGlot schema.
            If True, allow columns and tables not found in SQLGlot schema
        allow_anonymous_columns (bool): If False, all columns in final selection must have an explicit name or alias.
            If True, the name of columns from the final selection can be generated by the dialect
        allow_partial (bool): If False, raise exceptions if the schema returned is incomplete.
            If True, this function always returns a dictionary, even in cases of
            SQL parsing errors, missing table reference, unresolved `SELECT *`, etc.
        resource_name (str): The name of the resource to use in exceptions if available
    """
    try:
        expression: Any = sqlglot.maybe_parse(sql_query, dialect=dialect)
    except ParseError as e:
        if allow_partial:
            logger.debug(
                "Failed to parse the SQL query. Returning empty table schema because"
                " `allow_fail=True`"
            )
            return {}

        raise LineageFailedException(
            resource_name,
            f"Failed to parse the SQL query using dialect `{dialect}`.\nQuery:\n\t{sql_query}",
        ) from e

    if not isinstance(expression, sge.Select):
        if allow_partial:
            logger.debug(
                "Parsed SQL query is not a SELECT statement. Returning empty table schema because"
                " `allow_fail=True`"
            )
            return {}

        raise LineageFailedException(
            resource_name,
            "Parsed SQL query is not a SELECT statement. Received SQL expression of type"
            f" {expression.type}.",
        )

    if allow_anonymous_columns is False:
        for col in expression.selects:
            if col.output_name == "":
                raise LineageFailedException(
                    resource_name,
                    "Found anonymous column in SELECT statement. Use"
                    f" `allow_anonymous_columns=True` for permissive handling.\nColumn:\n\t{col}",
                )

    # false-y values `schema={}` or `schema=None` are identical to `infer_schema=True`
    try:
        expression = qualify(
            expression,
            schema=sqlglot_schema,
            dialect=dialect,
            infer_schema=infer_sqlglot_schema,
        )
    except OptimizeError as e:
        raise LineageFailedException(
            resource_name, "Failed to resolve SQL query against the schema received."
        ) from e

    expression = annotate_types(expression, schema=sqlglot_schema, dialect=dialect)

    dlt_table_schema = {}
    for col in expression.selects:
        if col.output_name == "*":
            if allow_partial is True:
                logger.debug(
                    "SELECT statement includes a `*` selection that can't be resolved. "
                    "Returning empty table schema because `allow_fail=True`"
                )
                continue

            raise LineageFailedException(
                resource_name,
                "SELECT statement includes a `*` selection that can't be resolved. Modify the"
                " query to select columns explicitly or limit `*` to known tables (e.g., `SELECT"
                " known_table.*`). Use `allow_fail=True` to return a partial dlt schema with"
                f" resolvable column hints.\nColumn:\n\t{col}",
            )

        dlt_hints = from_sqlglot_type(sqlglot_type=col.type)
        dlt_table_schema[col.output_name] = dict(name=col.output_name, **dlt_hints)

    return dlt_table_schema
