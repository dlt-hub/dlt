import logging
from typing import Any, Optional

import sqlglot
import sqlglot.expressions as sge
from sqlglot.dialects.dialect import DialectType
from sqlglot.errors import ParseError, OptimizeError
from sqlglot.schema import Schema as SQLGlotSchema
from sqlglot.optimizer.annotate_types import annotate_types
from sqlglot.optimizer.qualify import qualify

from dlt.destinations.sql_client import SqlClientBase

from dlt.common.libs.sqlglot import (
    to_sqlglot_type,
    from_sqlglot_type,
    set_metadata,
    get_metadata,
)
from dlt.common.schema import Schema
from dlt.common.schema.typing import (
    TTableSchemaColumns,
    TColumnSchema,
)
from dlt.transformations.exceptions import LineageFailedException


logger = logging.getLogger(__file__)


def create_sqlglot_schema(
    schema: Schema,
    sql_client: SqlClientBase[Any],
) -> Any:
    """Create an SQLGlot schema using a dlt Schema and the destination capabilities.

    The SQLGlot schema automatically includes the database and catalog names if available.
    This can allow cross-dataset transformations on the same physical location.
    """

    sqlglot_schema = {}  # MappingSchema(empty_schema, normalize=False)

    for table_name, table in schema.tables.items():
        column_mapping = {}
        for column_name, column in table["columns"].items():
            sqlglot_type = to_sqlglot_type(
                dlt_type=column["data_type"],
                nullable=column.get("nullable"),
                precision=column.get("precision"),
                scale=column.get("scale"),
                timezone=column.get("timezone"),
            )
            sqlglot_type = set_metadata(sqlglot_type, column)
            column_name = sql_client.capabilities.casefold_identifier(column_name)
            column_mapping[column_name] = sqlglot_type

        table_name = sql_client.make_qualified_table_name_path(table_name, escape=False)[-1]
        sqlglot_schema[table_name] = column_mapping

    # ensure proper nesting
    dataset_catalog = sql_client.make_qualified_table_name_path(None, escape=False)
    if len(dataset_catalog) == 2:
        catalog, database = dataset_catalog
        nested_schema = {catalog: {database: sqlglot_schema}}
    else:
        (database,) = dataset_catalog
        nested_schema = {database: sqlglot_schema}  # type: ignore

    # TODO: returning a "MappingSchema" here breaks snowflake for some reason, this needs further investigation

    return nested_schema


# NOTE even if `infer_sqlglot_schema=True`, some queries can have undetermined final columns
def compute_columns_schema(
    sql_query: str,
    sqlglot_schema: SQLGlotSchema,
    dialect: Optional[DialectType] = None,
    infer_sqlglot_schema: bool = True,
    allow_anonymous_columns: bool = True,
    allow_partial: bool = True,
) -> TTableSchemaColumns:
    """Compute the expected dlt columns schema for the output of an SQL SELECT query.

    Args:
        infer_sqlglot_schema (bool): If False, all columns and tables referenced must be derived from the SQLGlot schema.
            If True, allow columns and tables not found in SQLGlot schema
        allow_anonymous_columns (bool): If False, all columns in final selection must have an explicit name or alias.
            If True, the name of columns from the final selection can be generated by the dialect
        allow_partial (bool): If False, raise exceptions if the schema returned is incomplete.
            If True, this function always returns a dictionary, even in cases of
            SQL parsing errors, missing table reference, unresolved `SELECT *`, etc.
    """
    try:
        expression: Any = sqlglot.maybe_parse(sql_query, dialect=dialect)
    except ParseError as e:
        if allow_partial:
            logger.debug(
                "Failed to parse the SQL query. Returning empty table schema because"
                " `allow_fail=True`"
            )
            return {}

        raise LineageFailedException(
            f"Failed to parse the SQL query using dialect `{dialect}`.\nQuery:\n\t{sql_query}",
        ) from e

    if not isinstance(expression, sge.Select):
        if allow_partial:
            logger.debug(
                "Parsed SQL query is not a SELECT statement. Returning empty table schema because"
                " `allow_fail=True`"
            )
            return {}

        raise LineageFailedException(
            "Parsed SQL query is not a SELECT statement. Received SQL expression of type"
            f" {expression.type}.",
        )

    if allow_anonymous_columns is False:
        for col in expression.selects:
            if col.output_name == "":
                raise LineageFailedException(
                    "Found anonymous column in SELECT statement. Use"
                    f" `allow_anonymous_columns=True` for permissive handling.\nColumn:\n\t{col}",
                )

    # false-y values `schema={}` or `schema=None` are identical to `infer_schema=True`
    try:
        expression = qualify(
            expression,
            schema=sqlglot_schema,
            dialect=dialect,
            infer_schema=infer_sqlglot_schema,
        )
        assert isinstance(expression, sge.Select)  # qualify() preserves expression type `Select`
    except OptimizeError as e:
        raise LineageFailedException(
            "Failed to resolve SQL query against the schema received."
        ) from e

    expression = annotate_types(expression, schema=sqlglot_schema, dialect=dialect)

    dlt_table_schema: dict[str, TColumnSchema] = {}
    for col in expression.selects:
        if col.output_name == "*":
            if allow_partial is True:
                logger.debug(
                    "SELECT statement includes a `*` selection that can't be resolved. "
                    "Returning empty table schema because `allow_fail=True`"
                )
                continue

            raise LineageFailedException(
                "SELECT statement includes a `*` selection that can't be resolved. Modify the"
                " query to select columns explicitly or limit `*` to known tables (e.g., `SELECT"
                " known_table.*`). Use `allow_fail=True` to return a partial dlt schema with"
                f" resolvable column hints.\nColumn:\n\t{col}",
            )

        data_type_hints = from_sqlglot_type(sqlglot_type=col.type)
        additional_hints = get_metadata(sqlglot_type=col.type)
        # NOTE dictionary unpacking order matters; unpacking `data_type_hints` last ensures precedence.
        dlt_table_schema[col.output_name] = {
            "name": col.output_name,
            **additional_hints,
            **data_type_hints,
        }

    return dlt_table_schema
