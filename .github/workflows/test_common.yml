name: common | common

on:
  pull_request:
    branches:
      - master
      - devel
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

env:
  RUNTIME__LOG_LEVEL: ERROR
  RUNTIME__DLTHUB_TELEMETRY_ENDPOINT: ${{ secrets.RUNTIME__DLTHUB_TELEMETRY_ENDPOINT }}

  # we need the secrets only for the rest_api_pipeline tests which are in tests/sources
  # so we inject them only at the end
  SOURCES__GITHUB__ACCESS_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  # and also for the github_api_pipeline tests
  SOURCES__GITHUB_API_PIPELINE__ACCESS_TOKEN: ${{ secrets.GITHUB_TOKEN }}

jobs:
  get_docs_changes:
    name: docs changes
    uses: ./.github/workflows/get_docs_changes.yml

  run_common:
    name: test
    needs: get_docs_changes
    if: needs.get_docs_changes.outputs.changes_outside_docs == 'true'
    strategy:
      fail-fast: false
      matrix:
        include:

          # macos tests
          - os: macos-latest
            python-version: "3.11.x"
            shell: bash
            pytest_args: ""

          # linux tests
          - os: ubuntu-latest
            python-version: "3.9.x"
            shell: bash
            pytest_args: ""
          - os: ubuntu-latest
            python-version: "3.10.x"
            shell: bash
            pytest_args: ""
          - os: ubuntu-latest
            python-version: "3.11.x"
            shell: bash
            pytest_args: ""
          - os: ubuntu-latest
            python-version: "3.12.x"
            shell: bash
            pytest_args: ""
          - os: ubuntu-latest
            python-version: "3.13.x"
            shell: bash
            pytest_args: "" 
          
          # windows tests
          - os: windows-latest
            python-version: "3.11.x"
            shell: cmd
            pytest_args: '-m "not forked"'
          - os: windows-latest
            python-version: "3.13.x"
            shell: cmd
            pytest_args: '-m "not forked"'

    defaults:
      run:
        shell: ${{ matrix.shell }}
    runs-on: ${{ matrix.os }}

    steps:
      - name: Check out
        uses: actions/checkout@master

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install tzdata on windows
        run: |
          cd %USERPROFILE%
          curl https://data.iana.org/time-zones/releases/tzdata2021e.tar.gz --output tzdata.tar.gz
          mkdir tzdata
          tar --extract --file tzdata.tar.gz --directory tzdata
          mkdir %USERPROFILE%\Downloads\tzdata
          copy tzdata %USERPROFILE%\Downloads\tzdata
          curl https://raw.githubusercontent.com/unicode-org/cldr/master/common/supplemental/windowsZones.xml --output %USERPROFILE%\Downloads\tzdata\windowsZones.xml
        if: runner.os == 'Windows'

      - name: Install Poetry
        # https://github.com/snok/install-poetry#running-on-windows
        uses: snok/install-poetry@v1.3.2
        with:
          virtualenvs-create: true
          virtualenvs-in-project: true
          installer-parallel: true
          version: 1.8.5


      # NOTE: do not cache. we want to have a clean state each run and we upgrade depdendencies later
      # - name: Load cached venv
      #   id: cached-poetry-dependencies
      #   uses: actions/cache@v3
      #   with:
      #     # path: ${{ steps.pip-cache.outputs.dir }}
      #     path: .venv
      #     key: venv-${{ matrix.os }}-${{ matrix.python-version }}-${{ hashFiles('**/poetry.lock') }}

      - name: Install dependencies
        run: poetry install --no-interaction --with sentry-sdk

      - name: Run common tests with minimum dependencies
        run: |
          poetry run pytest tests/common tests/normalize tests/reflection tests/plugins tests/load/test_dummy_client.py tests/extract/test_extract.py tests/extract/test_sources.py tests/pipeline/test_pipeline_state.py ${{ matrix.pytest_args }}
        

      - name: Install duckdb dependencies
        run: poetry install --no-interaction -E duckdb --with sentry-sdk

      - name: Run pipeline smoke tests with minimum deps
        run: |
          poetry run pytest tests/pipeline/test_pipeline.py tests/pipeline/test_import_export_schema.py ${{ matrix.pytest_args }}

      - name: Install pyarrow
        run: poetry install --no-interaction -E duckdb -E cli -E parquet --with sentry-sdk

      - name: Run pipeline tests with pyarrow but no pandas installed
        run: |
          poetry run pytest tests/pipeline/test_pipeline_extra.py -k arrow ${{ matrix.pytest_args }}

      - name: Install pipeline and sources dependencies
        run: poetry install --no-interaction -E duckdb -E cli -E parquet -E deltalake -E sql_database --with sentry-sdk,pipeline,sources

      - name: Run extract and pipeline tests
        run: |
          poetry run pytest tests/extract tests/pipeline tests/libs tests/cli/common tests/destinations tests/sources ${{ matrix.pytest_args }}

      # here we upgrade sql alchemy to 2 an run the sql_database tests again
      - name: Upgrade sql alchemy
        run: poetry run pip install sqlalchemy==2.0.32

      - name: Run extract and pipeline tests 
        run: |
          poetry run pytest tests/sources/sql_database
        

      # - name: Install Pydantic 1.0
      #   run: pip install "pydantic<2"

      # - name: Run extract and pipeline tests
      #   run: |
      #     poetry run pytest tests/libs


      # test marimo app, does not work with python 3.13
      - name: Install dlt with duckdb and studio
        run: poetry install --no-interaction -E duckdb -E studio --with sentry-sdk,pipeline,sources,ibis
        if: matrix.python-version != '3.13.x'

      - name: Install playwright
        run: poetry run playwright install
        if: matrix.python-version != '3.13.x'

      # Run marimo studio unit tests
      - name: Run marimo studio unit tests
        run: |
          poetry run pytest tests/helpers/studio
        if: matrix.python-version != '3.13.x'

      # Run marimo e2e tests  
      - name: Run marimo e2e
        run: |
          poetry run marimo run --headless dlt/helpers/studio/app.py -- -- --pipelines_dir _storage/.dlt/pipelines/ --with_test_identifiers true & poetry run pytest --browser chromium tests/e2e
        if: matrix.python-version != '3.13.x'


  matrix_job_required_check:
    name: common | common tests
    needs: run_common
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Check matrix job results
        if: contains(needs.*.result, 'failure') || contains(needs.*.result, 'cancelled')
        run: |
          echo "One or more matrix job tests failed or were cancelled. You may need to re-run them." && exit 1
