name: common | common

on:
  pull_request:
    branches:
      - master
      - devel
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

env:
  RUNTIME__LOG_LEVEL: ERROR
  RUNTIME__DLTHUB_TELEMETRY_ENDPOINT: ${{ secrets.RUNTIME__DLTHUB_TELEMETRY_ENDPOINT }}

  # we need the secrets only for the rest_api_pipeline tests which are in tests/sources
  # so we inject them only at the end
  SOURCES__GITHUB__ACCESS_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  # and also for the github_api_pipeline tests
  SOURCES__GITHUB_API_PIPELINE__ACCESS_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  MAYBE_PYTEST_NOT_FORKED: ""  # Default fallback

jobs:
  get_docs_changes:
    name: docs changes
    uses: ./.github/workflows/get_docs_changes.yml

  run_common:
    name: test
    needs: get_docs_changes
    if: needs.get_docs_changes.outputs.changes_outside_docs == 'true'
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            python-version: "3.11.x"
            shell: bash
          - os: macos-latest
            python-version: "3.11.x"
            shell: bash      
          - os: windows-latest
            python-version: "3.11.x"
            shell: cmd
          - os: ubuntu-latest
            python-version: "3.9.x"
            shell: bash
          - os: ubuntu-latest
            python-version: "3.10.x"
            shell: bash
          - os: ubuntu-latest
            python-version: "3.12.x"
            shell: bash
          - os: ubuntu-latest
            python-version: "3.13.x"
            shell: bash

    defaults:
      run:
        shell: bash
    runs-on: ${{ matrix.os }}

    steps:
      - name: Check out
        uses: actions/checkout@master

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install tzdata on windows
        run: |
          cd %USERPROFILE%
          curl https://data.iana.org/time-zones/releases/tzdata2021e.tar.gz --output tzdata.tar.gz
          mkdir tzdata
          tar --extract --file tzdata.tar.gz --directory tzdata
          mkdir %USERPROFILE%\Downloads\tzdata
          copy tzdata %USERPROFILE%\Downloads\tzdata
          curl https://raw.githubusercontent.com/unicode-org/cldr/master/common/supplemental/windowsZones.xml --output %USERPROFILE%\Downloads\tzdata\windowsZones.xml
        if: runner.os == 'Windows'

      - name: Install Poetry
        # https://github.com/snok/install-poetry#running-on-windows
        uses: snok/install-poetry@v1.3.2
        with:
          virtualenvs-create: true
          virtualenvs-in-project: true
          installer-parallel: true
          version: 1.8.5

      # This step (in conjunction with appending MAYBE_PYTEST_NOT_FORKED to the pytest commands below) makes sure that tests marked as forked are not run on Windows
      - name: Prepare not forked statement
        run: |
          echo 'MAYBE_PYTEST_NOT_FORKED=-m "not forked"' >> "$GITHUB_ENV"
        if: runner.os == 'Windows'



      # NOTE: do not cache. we want to have a clean state each run and we upgrade depdendencies later
      # - name: Load cached venv
      #   id: cached-poetry-dependencies
      #   uses: actions/cache@v3
      #   with:
      #     # path: ${{ steps.pip-cache.outputs.dir }}
      #     path: .venv
      #     key: venv-${{ matrix.os }}-${{ matrix.python-version }}-${{ hashFiles('**/poetry.lock') }}

      - name: Install dependencies
        run: poetry install --no-interaction --with sentry-sdk

      - run: |
          poetry run pytest tests/common tests/normalize tests/reflection tests/plugins tests/load/test_dummy_client.py tests/extract/test_extract.py tests/extract/test_sources.py tests/pipeline/test_pipeline_state.py $MAYBE_PYTEST_NOT_FORKED
        name: Run common tests with minimum dependencies Linux/MAC

      - name: Install duckdb dependencies
        run: poetry install --no-interaction -E duckdb --with sentry-sdk

      - run: |
          poetry run pytest tests/pipeline/test_pipeline.py tests/pipeline/test_import_export_schema.py $MAYBE_PYTEST_NOT_FORKED
        name: Run pipeline smoke tests with minimum deps Linux/MAC

      - name: Install pyarrow
        run: poetry install --no-interaction -E duckdb -E cli -E parquet --with sentry-sdk

      - run: |
          poetry run pytest tests/pipeline/test_pipeline_extra.py -k arrow $MAYBE_PYTEST_NOT_FORKED
        name: Run pipeline tests with pyarrow but no pandas installed

      - name: Install pipeline and sources dependencies
        run: poetry install --no-interaction -E duckdb -E cli -E parquet -E deltalake -E sql_database --with sentry-sdk,pipeline,sources

      - run: |
          poetry run pytest tests/extract tests/pipeline tests/libs tests/cli/common tests/destinations tests/sources
        name: Run extract and pipeline tests Linux/MAC

      # here we upgrade sql alchemy to 2 an run the sql_database tests again
      - name: Upgrade sql alchemy
        run: poetry run pip install sqlalchemy==2.0.32

      - run: |
          poetry run pytest tests/sources/sql_database
        name: Run extract and pipeline tests Linux/MAC

      # - name: Install Pydantic 1.0
      #   run: pip install "pydantic<2"

      # - run: |
      #     poetry run pytest tests/libs
      #   name: Run extract and pipeline tests Linux/MAC


  matrix_job_required_check:
    name: common | common tests
    needs: run_common
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Check matrix job results
        if: contains(needs.*.result, 'failure') || contains(needs.*.result, 'cancelled')
        run: |
          echo "One or more matrix job tests failed or were cancelled. You may need to re-run them." && exit 1
